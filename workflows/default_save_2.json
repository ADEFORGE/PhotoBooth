{
  "3": {
    "inputs": {
      "control_net_name": "1.5\\control_v11p_sd15_lineart_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "7": {
    "inputs": {
      "images": [
        "23",
        5
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "9": {
    "inputs": {
      "upscale_model": [
        "14",
        0
      ],
      "image": [
        "23",
        5
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "12": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "9",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "14": {
    "inputs": {
      "model_name": "RealESRGAN_x2.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "16": {
    "inputs": {
      "image": [
        "17",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "17": {
    "inputs": {
      "image": "WIN_20250715_14_18_05_Pro.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "19": {
    "inputs": {
      "ckpt_name": "dreamshaper_8.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -1,
      "lora_name": "None",
      "lora_model_strength": 1.0000000000000002,
      "lora_clip_strength": 1.0000000000000002,
      "positive": [
        "88",
        0
      ],
      "negative": "embedding:BadDream, embedding:UnrealisticDream, embedding:FastNegativeV2, (bare chest, breasts, visible anatomy, nude:1), ugly, deformed, noisy, blurry, low contrast, modern clothing, plastic, low detail, extra limbs, blurry, distorted face, text, watermark, poorly drawn hands, naked, muscles, nsfw",
      "token_normalization": "mean",
      "weight_interpretation": "comfy",
      "empty_latent_width": [
        "20",
        0
      ],
      "empty_latent_height": [
        "21",
        0
      ],
      "batch_size": 1,
      "cnet_stack": [
        "26",
        0
      ]
    },
    "class_type": "Efficient Loader",
    "_meta": {
      "title": "Efficient Loader"
    }
  },
  "20": {
    "inputs": {
      "expression": "a//b\n\n",
      "a": [
        "16",
        0
      ],
      "b": [
        "71",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression üêç"
    }
  },
  "21": {
    "inputs": {
      "expression": "a//b",
      "a": [
        "16",
        1
      ],
      "b": [
        "71",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression üêç"
    }
  },
  "23": {
    "inputs": {
      "seed": 1089789284519586,
      "steps": 10,
      "cfg": 4.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "AYS SD1",
      "denoise": 1,
      "preview_method": "taesd",
      "vae_decode": "true",
      "model": [
        "93",
        0
      ],
      "positive": [
        "19",
        1
      ],
      "negative": [
        "19",
        2
      ],
      "latent_image": [
        "19",
        3
      ],
      "optional_vae": [
        "19",
        4
      ]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "26": {
    "inputs": {
      "strength": 0.5000000000000001,
      "start_percent": 0,
      "end_percent": 0.9000000000000002,
      "control_net": [
        "3",
        0
      ],
      "image": [
        "45",
        0
      ],
      "cnet_stack": [
        "47",
        0
      ]
    },
    "class_type": "Control Net Stacker",
    "_meta": {
      "title": "Control Net Stacker"
    }
  },
  "45": {
    "inputs": {
      "preprocessor": "LineArtPreprocessor",
      "resolution": [
        "16",
        0
      ],
      "image": [
        "17",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  },
  "47": {
    "inputs": {
      "strength": 0.5000000000000001,
      "start_percent": 0,
      "end_percent": 1,
      "control_net": [
        "48",
        0
      ],
      "image": [
        "96",
        0
      ]
    },
    "class_type": "Control Net Stacker",
    "_meta": {
      "title": "Control Net Stacker"
    }
  },
  "48": {
    "inputs": {
      "control_net_name": "1.5\\control_v11e_sd15_ip2p_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "71": {
    "inputs": {
      "value": 2.1
    },
    "class_type": "PrimitiveFloat",
    "_meta": {
      "title": "Float"
    }
  },
  "85": {
    "inputs": {
      "images": [
        "17",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "87": {
    "inputs": {
      "images": [
        "45",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "88": {
    "inputs": {
      "text": "Transform this person into a claymation character. Give them a handcrafted look with soft, rounded features, visible fingerprints or texture in the clay, and slightly exaggerated expressions. Use stop-motion lighting and a warm, tactile feel. Background should look like a miniature set made of clay or craft materials. Use playdoh colors, and add fingerprint details on the surfaces"
    },
    "class_type": "Text Multiline",
    "_meta": {
      "title": "Text Multiline"
    }
  },
  "92": {
    "inputs": {
      "preset": "FACEID",
      "lora_strength": 0.6,
      "provider": "CPU",
      "model": [
        "19",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoaderFaceID",
    "_meta": {
      "title": "IPAdapter Unified Loader FaceID"
    }
  },
  "93": {
    "inputs": {
      "weight": 1.0000000000000002,
      "weight_faceidv2": 1.0000000000000002,
      "weight_type": "composition",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": [
        "92",
        0
      ],
      "ipadapter": [
        "92",
        1
      ],
      "image": [
        "17",
        0
      ]
    },
    "class_type": "IPAdapterFaceID",
    "_meta": {
      "title": "IPAdapter FaceID"
    }
  },
  "96": {
    "inputs": {
      "preprocessor": "ImageLuminanceDetector",
      "resolution": [
        "16",
        0
      ],
      "image": [
        "17",
        0
      ]
    },
    "class_type": "AIO_Preprocessor",
    "_meta": {
      "title": "AIO Aux Preprocessor"
    }
  }
}